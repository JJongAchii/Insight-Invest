# AWS Athena ê¸°ë°˜ ì•„í‚¤í…ì²˜ ê°€ì´ë“œ

## ğŸ¯ Athena vs Trino: ì¬í‰ê°€

### ë‹¹ì‹ ì˜ ìš”êµ¬ì‚¬í•­ ë‹¤ì‹œ ë³´ê¸°
1. âœ… Pandas ì œê±° â†’ Arrow/SQL ê¸°ë°˜
2. âœ… ìŠ¤í‚¤ë§ˆ ë¶„ì‚° â†’ ì—¬ëŸ¬ Iceberg ìŠ¤í‚¤ë§ˆ
3. âœ… í¬ë¡œìŠ¤ ìŠ¤í‚¤ë§ˆ ì¡°ì¸ â†’ SQLë¡œ í•´ê²°

### ğŸ¤” Athenaê°€ Trinoë³´ë‹¤ ë‚˜ì€ ì 

| í•­ëª© | Athena | Trino |
|------|--------|-------|
| **ì¸í”„ë¼ ê´€ë¦¬** | âœ…âœ…âœ… ì™„ì „ ì„œë²„ë¦¬ìŠ¤ | âŒ ECS í´ëŸ¬ìŠ¤í„° ê´€ë¦¬ í•„ìš” |
| **ë¹„ìš©** | âœ…âœ…âœ… $0.25/ì›” | âš ï¸ $12-42/ì›” |
| **í™•ì¥ì„±** | âœ…âœ…âœ… ìë™ ë¬´í•œ í™•ì¥ | âš ï¸ Worker ìˆ˜ë™ ì¡°ì • |
| **AWS í†µí•©** | âœ…âœ…âœ… ë„¤ì´í‹°ë¸Œ | âš ï¸ ë³„ë„ ì„¤ì • |
| **ìœ ì§€ë³´ìˆ˜** | âœ…âœ…âœ… ì—†ìŒ | âš ï¸ ì—…ê·¸ë ˆì´ë“œ, ëª¨ë‹ˆí„°ë§ |
| **ì‹œì‘ ë¹„ìš©** | âœ…âœ…âœ… $0 (ì‚¬ìš©í•œ ë§Œí¼) | âŒ ìµœì†Œ $12/ì›” |
| **ì‘ë‹µ ì†ë„** | âš ï¸ 3-5ì´ˆ (ì½œë“œ ìŠ¤íƒ€íŠ¸) | âœ… < 500ms |
| **ì‹¤ì‹œê°„ ì¿¼ë¦¬** | âš ï¸ ë¹„ë™ê¸° ì²˜ë¦¬ | âœ… ë™ê¸° ì²˜ë¦¬ |

### ğŸ’¡ ê²°ë¡ : **API íŒ¨í„´ì— ë”°ë¼ Athenaê°€ ë” ë‚˜ì„ ìˆ˜ ìˆìŒ!**

```
ì‹¤ì‹œê°„ ëŒ€ì‹œë³´ë“œ (ì´ˆ ë‹¨ìœ„ ì‘ë‹µ) â†’ Trino
ë°°ì¹˜/ë¶„ì„ ì¿¼ë¦¬ (ë¶„ ë‹¨ìœ„ ì‘ë‹µ) â†’ Athena â­
ë¹„ìš© ìµœìš°ì„  â†’ Athena â­â­â­
```

---

## ğŸ—ï¸ Athena ì•„í‚¤í…ì²˜

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚            FastAPI (API Layer)                          â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”          â”‚
â”‚  â”‚  import boto3                             â”‚          â”‚
â”‚  â”‚  athena = boto3.client('athena')         â”‚          â”‚
â”‚  â”‚  result = query_athena_async(sql)        â”‚          â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜          â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                 â”‚
                 â–¼
      â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
      â”‚   AWS Athena         â”‚
      â”‚   (Serverless)       â”‚
      â”‚                      â”‚
      â”‚  - Query Planning    â”‚
      â”‚  - Auto Scaling      â”‚
      â”‚  - Arrow Format      â”‚
      â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
             â”‚
     â”Œâ”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
     â”‚                          â”‚
     â–¼                          â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  AWS Glue   â”‚        â”‚  S3 Iceberg  â”‚
â”‚  Catalog    â”‚        â”‚  (ë¶„ì‚° ìŠ¤í‚¤ë§ˆ) â”‚
â”‚             â”‚        â”‚              â”‚
â”‚ - market_   â”‚        â”‚ market_data/ â”‚
â”‚   data      â”‚        â”‚ portfolio/   â”‚
â”‚ - portfolio â”‚        â”‚ analytics/   â”‚
â”‚ - analytics â”‚        â”‚ reference/   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜        â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## ğŸ’» Athena êµ¬í˜„ ê°€ì´ë“œ

### 1. Glue Catalog ì„¤ì • (ìŠ¤í‚¤ë§ˆ ë¶„ì‚°)

```bash
# 1. ì—¬ëŸ¬ ë°ì´í„°ë² ì´ìŠ¤(ìŠ¤í‚¤ë§ˆ) ìƒì„±
aws glue create-database --database-input '{
  "Name": "market_data",
  "Description": "Stock market data"
}'

aws glue create-database --database-input '{
  "Name": "portfolio",
  "Description": "Portfolio data"
}'

aws glue create-database --database-input '{
  "Name": "analytics",
  "Description": "Analytics and metrics"
}'

aws glue create-database --database-input '{
  "Name": "reference",
  "Description": "Reference data"
}'
```

### 2. Iceberg í…Œì´ë¸” ìƒì„± (ê° ìŠ¤í‚¤ë§ˆë³„)

```python
# server/scripts/create_iceberg_tables_athena.py
import boto3
from pyiceberg.catalog import load_catalog

# Glue Catalog ì—°ê²°
catalog = load_catalog(
    "glue",
    **{
        "type": "glue",
        "s3.region": "ap-northeast-2",
        "warehouse": "s3://insight-invest-datalake/warehouse"
    }
)

# 1. market_data ìŠ¤í‚¤ë§ˆì˜ í…Œì´ë¸”
def create_market_data_tables():
    """ì£¼ê°€ ë°ì´í„° í…Œì´ë¸”"""

    # US ì£¼ì‹ ê°€ê²©
    catalog.create_table(
        identifier="market_data.us_stocks_price",
        schema=Schema(
            NestedField(1, "meta_id", IntegerType(), required=True),
            NestedField(2, "trade_date", DateType(), required=True),
            NestedField(3, "close", FloatType()),
            NestedField(4, "adj_close", FloatType()),
            NestedField(5, "gross_return", FloatType()),
        ),
        partition_spec=PartitionSpec(
            PartitionField(
                source_id=2,
                field_id=1000,
                transform=MonthTransform(),
                name="trade_month"
            )
        ),
        properties={
            "write.format.default": "parquet",
            "write.parquet.compression-codec": "zstd",
        }
    )

    # KR ì£¼ì‹ ê°€ê²©
    catalog.create_table(
        identifier="market_data.kr_stocks_price",
        schema=...,  # ë™ì¼
        partition_spec=...,
    )

# 2. portfolio ìŠ¤í‚¤ë§ˆì˜ í…Œì´ë¸”
def create_portfolio_tables():
    """í¬íŠ¸í´ë¦¬ì˜¤ ê´€ë ¨ í…Œì´ë¸”"""

    catalog.create_table(
        identifier="portfolio.tb_nav",
        schema=Schema(
            NestedField(1, "trade_date", DateType(), required=True),
            NestedField(2, "port_id", IntegerType(), required=True),
            NestedField(3, "value", FloatType(), required=True),
        ),
        partition_spec=PartitionSpec(
            PartitionField(
                source_id=1,
                field_id=1000,
                transform=MonthTransform(),
                name="trade_month"
            )
        )
    )

    catalog.create_table(
        identifier="portfolio.tb_rebalance",
        schema=Schema(
            NestedField(1, "rebal_date", DateType(), required=True),
            NestedField(2, "port_id", IntegerType(), required=True),
            NestedField(3, "meta_id", IntegerType(), required=True),
            NestedField(4, "weight", FloatType(), required=True),
        ),
        partition_spec=PartitionSpec(
            PartitionField(
                source_id=1,
                field_id=1000,
                transform=YearTransform(),
                name="rebal_year"
            )
        )
    )

# 3. analytics ìŠ¤í‚¤ë§ˆì˜ í…Œì´ë¸”
def create_analytics_tables():
    """ë¶„ì„ ë©”íŠ¸ë¦­ í…Œì´ë¸”"""

    catalog.create_table(
        identifier="analytics.tb_metrics",
        schema=Schema(
            NestedField(1, "port_id", IntegerType(), required=True),
            NestedField(2, "calculation_date", DateType(), required=True),
            NestedField(3, "sharpe", FloatType()),
            NestedField(4, "mdd", FloatType()),
            NestedField(5, "ann_ret", FloatType()),
            NestedField(6, "ann_vol", FloatType()),
        )
    )
```

### 3. Athena í´ë¼ì´ì–¸íŠ¸ (Python)

```python
# server/db/athena_client.py
import boto3
import time
import pyarrow as pa
import pyarrow.parquet as pq
from typing import List, Dict, Optional
from functools import lru_cache
import os

class AthenaClient:
    """
    Athena í´ë¼ì´ì–¸íŠ¸ (Arrow ë„¤ì´í‹°ë¸Œ, Pandas ì—†ìŒ!)
    """

    def __init__(self):
        self.client = boto3.client('athena', region_name='ap-northeast-2')
        self.s3_output = 's3://insight-invest-athena-results/'
        self.database = 'market_data'  # ê¸°ë³¸ ë°ì´í„°ë² ì´ìŠ¤

    def execute_query(
        self,
        sql: str,
        database: str = None,
        wait: bool = True
    ) -> str:
        """
        Athena ì¿¼ë¦¬ ì‹¤í–‰

        Args:
            sql: SQL ì¿¼ë¦¬
            database: ë°ì´í„°ë² ì´ìŠ¤ (ìŠ¤í‚¤ë§ˆ)
            wait: ì™„ë£Œ ëŒ€ê¸° ì—¬ë¶€

        Returns:
            query_execution_id
        """
        response = self.client.start_query_execution(
            QueryString=sql,
            QueryExecutionContext={
                'Database': database or self.database
            },
            ResultConfiguration={
                'OutputLocation': self.s3_output,
                'EncryptionConfiguration': {
                    'EncryptionOption': 'SSE_S3'
                }
            }
        )

        query_id = response['QueryExecutionId']

        if wait:
            self._wait_for_query(query_id)

        return query_id

    def _wait_for_query(
        self,
        query_id: str,
        max_attempts: int = 60
    ):
        """ì¿¼ë¦¬ ì™„ë£Œ ëŒ€ê¸° (ìµœëŒ€ 60ì´ˆ)"""

        for attempt in range(max_attempts):
            response = self.client.get_query_execution(
                QueryExecutionId=query_id
            )

            state = response['QueryExecution']['Status']['State']

            if state == 'SUCCEEDED':
                return
            elif state in ['FAILED', 'CANCELLED']:
                reason = response['QueryExecution']['Status'].get(
                    'StateChangeReason', 'Unknown'
                )
                raise Exception(f"Query {state}: {reason}")

            time.sleep(1)

        raise TimeoutError(f"Query timeout after {max_attempts}s")

    def get_results_arrow(self, query_id: str) -> pa.Table:
        """
        ì¿¼ë¦¬ ê²°ê³¼ë¥¼ Arrow Tableë¡œ ë°˜í™˜ (Pandas ì—†ìŒ!)
        """
        # S3ì—ì„œ ê²°ê³¼ íŒŒì¼ ê²½ë¡œ ê°€ì ¸ì˜¤ê¸°
        response = self.client.get_query_execution(
            QueryExecutionId=query_id
        )

        output_location = response['QueryExecution']['ResultConfiguration']['OutputLocation']

        # S3ì—ì„œ Parquet íŒŒì¼ ì½ê¸° (AthenaëŠ” ê²°ê³¼ë¥¼ Parquetë¡œ ì €ì¥)
        # Arrowë¡œ ì§ì ‘ ì½ê¸°!
        import s3fs
        fs = s3fs.S3FileSystem()

        with fs.open(output_location.replace('s3://', ''), 'rb') as f:
            table = pq.read_table(f)

        return table

    def query_to_arrow(self, sql: str, database: str = None) -> pa.Table:
        """
        SQL ì‹¤í–‰ â†’ Arrow Table ë°˜í™˜ (ì›ìŠ¤í†±)
        """
        query_id = self.execute_query(sql, database, wait=True)
        return self.get_results_arrow(query_id)

    def query_to_json(self, sql: str, database: str = None) -> List[Dict]:
        """
        SQL ì‹¤í–‰ â†’ JSON ë°˜í™˜ (FastAPIìš©)
        """
        arrow_table = self.query_to_arrow(sql, database)
        return arrow_table.to_pylist()

    def query_to_parquet(
        self,
        sql: str,
        output_path: str,
        database: str = None
    ):
        """
        SQL ì‹¤í–‰ â†’ Parquet ì €ì¥ (ëŒ€ìš©ëŸ‰ ë°°ì¹˜)
        """
        arrow_table = self.query_to_arrow(sql, database)
        pq.write_table(arrow_table, output_path, compression='zstd')


# ì‹±ê¸€í†¤ ì¸ìŠ¤í„´ìŠ¤
@lru_cache(maxsize=1)
def get_athena_client() -> AthenaClient:
    return AthenaClient()
```

### 4. FastAPI í†µí•© (Pandas ì—†ìŒ!)

```python
# server/app/routers/price_athena.py
from fastapi import APIRouter, Query, HTTPException
from typing import List, Dict
from db.athena_client import get_athena_client

router = APIRouter(prefix="/api/v2/price", tags=["price-v2-athena"])

athena = get_athena_client()


@router.get("/daily")
def get_daily_prices(
    ticker: str,
    start_date: str,
    end_date: str = None,
) -> List[Dict]:
    """
    ì¼ë³„ ê°€ê²© ì¡°íšŒ (Athena + Arrow)
    âœ… Pandas ì—†ìŒ
    âœ… í¬ë¡œìŠ¤ ìŠ¤í‚¤ë§ˆ ì¡°ì¸ (market_data + reference)
    """

    sql = f"""
    SELECT
        p.trade_date,
        p.close,
        p.adj_close,
        p.gross_return,
        m.ticker,
        m.name,
        m.sector
    FROM market_data.us_stocks_price p
    JOIN reference.tb_meta m
        ON p.meta_id = m.meta_id
    WHERE m.ticker = '{ticker}'
      AND p.trade_date >= DATE '{start_date}'
    """

    if end_date:
        sql += f" AND p.trade_date <= DATE '{end_date}'"

    sql += " ORDER BY p.trade_date"

    # Arrow â†’ JSON (Pandas ì—†ìŒ!)
    return athena.query_to_json(sql, database='market_data')


@router.get("/aggregate")
def get_aggregate_stats(
    tickers: List[str] = Query(...),
    start_date: str = Query(...),
) -> List[Dict]:
    """
    ì§‘ê³„ í†µê³„ (Athena ë¶„ì‚° ì²˜ë¦¬)
    âœ… Pandas ì—†ìŒ
    âœ… í¬ë¡œìŠ¤ ìŠ¤í‚¤ë§ˆ ì¡°ì¸
    """

    ticker_list = "','".join(tickers)

    sql = f"""
    SELECT
        m.ticker,
        m.name,
        m.sector,
        COUNT(*) as trading_days,
        AVG(p.adj_close) as avg_price,
        STDDEV(p.adj_close) as price_std,
        AVG(p.gross_return) as avg_return,
        STDDEV(p.gross_return) as volatility,
        MIN(p.adj_close) as min_price,
        MAX(p.adj_close) as max_price
    FROM market_data.us_stocks_price p
    JOIN reference.tb_meta m
        ON p.meta_id = m.meta_id
    WHERE m.ticker IN ('{ticker_list}')
      AND p.trade_date >= DATE '{start_date}'
    GROUP BY m.ticker, m.name, m.sector
    ORDER BY m.ticker
    """

    return athena.query_to_json(sql, database='market_data')


@router.get("/portfolio-performance")
def get_portfolio_performance(
    port_id: int,
    start_date: str,
) -> List[Dict]:
    """
    ë³µì¡í•œ í¬ë¡œìŠ¤ ìŠ¤í‚¤ë§ˆ ì¡°ì¸ (3ê°œ ìŠ¤í‚¤ë§ˆ)
    âœ… market_data + portfolio + analytics
    âœ… Athenaê°€ ìë™ ìµœì í™”
    """

    sql = f"""
    WITH daily_portfolio AS (
        SELECT
            p.trade_date,
            SUM(p.adj_close * r.weight) as portfolio_value
        FROM market_data.us_stocks_price p
        JOIN portfolio.tb_rebalance r
            ON p.meta_id = r.meta_id
            AND p.trade_date >= r.rebal_date
        WHERE r.port_id = {port_id}
          AND p.trade_date >= DATE '{start_date}'
        GROUP BY p.trade_date
    )
    SELECT
        dp.trade_date,
        dp.portfolio_value,
        n.value as nav_value,
        m.sharpe,
        m.mdd,
        m.ann_ret,
        m.ann_vol
    FROM daily_portfolio dp
    JOIN portfolio.tb_nav n
        ON dp.trade_date = n.trade_date
        AND n.port_id = {port_id}
    LEFT JOIN analytics.tb_metrics m
        ON m.port_id = {port_id}
        AND m.calculation_date = dp.trade_date
    ORDER BY dp.trade_date
    """

    return athena.query_to_json(sql, database='market_data')


@router.get("/cross-market-analysis")
def cross_market_analysis(
    us_ticker: str,
    kr_ticker: str,
    start_date: str,
) -> List[Dict]:
    """
    ë¯¸êµ­ vs í•œêµ­ ì£¼ì‹ ë¹„êµ (í¬ë¡œìŠ¤ í…Œì´ë¸” ì¡°ì¸)
    âœ… us_stocks_price + kr_stocks_price ì¡°ì¸
    """

    sql = f"""
    SELECT
        us.trade_date,
        us.adj_close as us_price,
        kr.adj_close as kr_price,
        us.gross_return as us_return,
        kr.gross_return as kr_return,
        CORR(us.gross_return, kr.gross_return) OVER (
            ORDER BY us.trade_date
            ROWS BETWEEN 19 PRECEDING AND CURRENT ROW
        ) as rolling_correlation_20d
    FROM (
        SELECT p.trade_date, p.adj_close, p.gross_return
        FROM market_data.us_stocks_price p
        JOIN reference.tb_meta m ON p.meta_id = m.meta_id
        WHERE m.ticker = '{us_ticker}'
          AND p.trade_date >= DATE '{start_date}'
    ) us
    FULL OUTER JOIN (
        SELECT p.trade_date, p.adj_close, p.gross_return
        FROM market_data.kr_stocks_price p
        JOIN reference.tb_meta m ON p.meta_id = m.meta_id
        WHERE m.ticker = '{kr_ticker}'
          AND p.trade_date >= DATE '{start_date}'
    ) kr
    ON us.trade_date = kr.trade_date
    ORDER BY us.trade_date
    """

    return athena.query_to_json(sql, database='market_data')
```

### 5. ë¹„ë™ê¸° ì¿¼ë¦¬ íŒ¨í„´ (3-5ì´ˆ ì§€ì—° í•´ê²°)

```python
# server/app/routers/price_athena_async.py
from fastapi import APIRouter, BackgroundTasks, HTTPException
from typing import Dict
import uuid
from db.athena_client import get_athena_client

router = APIRouter(prefix="/api/v2/query", tags=["async-query"])

athena = get_athena_client()

# ì¿¼ë¦¬ ê²°ê³¼ ìºì‹œ (Redis ë˜ëŠ” ë©”ëª¨ë¦¬)
query_cache: Dict[str, Dict] = {}


@router.post("/submit")
def submit_query(sql: str) -> Dict:
    """
    ë¹„ë™ê¸° ì¿¼ë¦¬ ì œì¶œ

    Returns:
        {"query_id": "uuid", "status": "RUNNING"}
    """
    # Athena ì¿¼ë¦¬ ì‹œì‘ (ëŒ€ê¸° ì•ˆ í•¨)
    athena_query_id = athena.execute_query(sql, wait=False)

    # ê³ ìœ  ID ìƒì„±
    query_id = str(uuid.uuid4())

    # ìºì‹œì— ì €ì¥
    query_cache[query_id] = {
        "athena_query_id": athena_query_id,
        "status": "RUNNING",
        "result": None
    }

    return {
        "query_id": query_id,
        "status": "RUNNING"
    }


@router.get("/status/{query_id}")
def get_query_status(query_id: str) -> Dict:
    """
    ì¿¼ë¦¬ ìƒíƒœ í™•ì¸

    Returns:
        {"status": "RUNNING" | "SUCCEEDED" | "FAILED"}
    """
    if query_id not in query_cache:
        raise HTTPException(404, "Query not found")

    cached = query_cache[query_id]
    athena_query_id = cached["athena_query_id"]

    # Athena ìƒíƒœ í™•ì¸
    response = athena.client.get_query_execution(
        QueryExecutionId=athena_query_id
    )

    state = response['QueryExecution']['Status']['State']

    # ìºì‹œ ì—…ë°ì´íŠ¸
    cached["status"] = state

    return {
        "query_id": query_id,
        "status": state
    }


@router.get("/result/{query_id}")
def get_query_result(query_id: str) -> List[Dict]:
    """
    ì¿¼ë¦¬ ê²°ê³¼ ì¡°íšŒ

    Returns:
        ê²°ê³¼ ë°ì´í„° (Arrow â†’ JSON)
    """
    if query_id not in query_cache:
        raise HTTPException(404, "Query not found")

    cached = query_cache[query_id]

    # ì´ë¯¸ ìºì‹œëœ ê²°ê³¼ê°€ ìˆìœ¼ë©´ ë°˜í™˜
    if cached["result"]:
        return cached["result"]

    # ìƒíƒœ í™•ì¸
    status_response = get_query_status(query_id)

    if status_response["status"] == "RUNNING":
        raise HTTPException(202, "Query still running")
    elif status_response["status"] == "FAILED":
        raise HTTPException(500, "Query failed")

    # ê²°ê³¼ ì¡°íšŒ (Arrow â†’ JSON)
    athena_query_id = cached["athena_query_id"]
    result = athena.get_results_arrow(athena_query_id).to_pylist()

    # ìºì‹œì— ì €ì¥
    cached["result"] = result

    return result


# ì‚¬ìš© ì˜ˆì‹œ (Frontend)
"""
1. ì¿¼ë¦¬ ì œì¶œ
POST /api/v2/query/submit
Body: {"sql": "SELECT ..."}
Response: {"query_id": "abc-123", "status": "RUNNING"}

2. ìƒíƒœ í´ë§ (1ì´ˆë§ˆë‹¤)
GET /api/v2/query/status/abc-123
Response: {"status": "RUNNING"}

3. ì™„ë£Œ í›„ ê²°ê³¼ ì¡°íšŒ
GET /api/v2/query/result/abc-123
Response: [{"trade_date": "2024-01-01", ...}]
"""
```

### 6. ë°±í…ŒìŠ¤íŠ¸ ëª¨ë“ˆ (Arrow ë„¤ì´í‹°ë¸Œ)

```python
# server/module/backtest_athena.py
from db.athena_client import get_athena_client
import pyarrow as pa
import pyarrow.compute as pc
from typing import Dict

athena = get_athena_client()


class BacktestAthena:
    """
    Athena + Arrow ê¸°ë°˜ ë°±í…ŒìŠ¤íŠ¸ (Pandas ì—†ìŒ!)
    """

    def get_price_data(
        self,
        meta_ids: List[int],
        start_date: str,
        end_date: str = None
    ) -> pa.Table:
        """
        ê°€ê²© ë°ì´í„° ì¡°íšŒ â†’ Arrow Table
        """
        meta_id_list = ','.join(map(str, meta_ids))

        sql = f"""
        SELECT
            meta_id,
            trade_date,
            adj_close
        FROM market_data.us_stocks_price
        WHERE meta_id IN ({meta_id_list})
          AND trade_date >= DATE '{start_date}'
        """

        if end_date:
            sql += f" AND trade_date <= DATE '{end_date}'"

        sql += " ORDER BY trade_date, meta_id"

        return athena.query_to_arrow(sql)

    def calculate_returns(self, price_table: pa.Table) -> pa.Table:
        """
        ìˆ˜ìµë¥  ê³„ì‚° (Arrow Compute, Pandas ì—†ìŒ!)
        """
        # Arrow Computeë¡œ ë²¡í„° ì—°ì‚°
        adj_close = price_table['adj_close']

        # meta_idë³„ë¡œ ê·¸ë£¹í™”í•˜ì—¬ ì´ì „ ê°’ ê³„ì‚°
        # (Arrowì˜ window function í™œìš©)

        # ê°„ë‹¨í•œ ë²„ì „: ì „ì²´ shift (ì‹¤ì œë¡œëŠ” ê·¸ë£¹ë³„ ì²˜ë¦¬ í•„ìš”)
        prev_close = pc.shift(adj_close, 1)

        # ìˆ˜ìµë¥  = (í˜„ì¬ - ì´ì „) / ì´ì „
        returns = pc.divide(
            pc.subtract(adj_close, prev_close),
            prev_close
        )

        # ìƒˆ ì»¬ëŸ¼ ì¶”ê°€
        return price_table.append_column('returns', returns)

    def calculate_portfolio_value(
        self,
        price_table: pa.Table,
        weights: Dict[int, float]  # {meta_id: weight}
    ) -> pa.Table:
        """
        í¬íŠ¸í´ë¦¬ì˜¤ ê°€ì¹˜ ê³„ì‚° (Arrow)
        """
        # Arrowë¡œ ê°€ì¤‘ í‰ê·  ê³„ì‚°
        meta_ids = price_table['meta_id'].to_pylist()
        adj_closes = price_table['adj_close'].to_numpy()

        # ê°€ì¤‘ì¹˜ ì ìš©
        weighted_prices = []
        for meta_id, price in zip(meta_ids, adj_closes):
            weight = weights.get(meta_id, 0)
            weighted_prices.append(price * weight)

        # Arrow Arrayë¡œ ë³€í™˜
        portfolio_values = pa.array(weighted_prices)

        return price_table.append_column('portfolio_value', portfolio_values)

    def calculate_metrics(self, returns_table: pa.Table) -> Dict:
        """
        ì„±ê³¼ ë©”íŠ¸ë¦­ ê³„ì‚° (Arrow Compute)
        """
        returns = returns_table['returns']

        # Athenaì—ì„œ ì§ì ‘ ê³„ì‚°í•˜ëŠ” ê²ƒì´ ë” íš¨ìœ¨ì !
        sql = f"""
        WITH returns_data AS (
            SELECT
                returns,
                SUM(returns) OVER (ORDER BY trade_date) as cumulative_return
            FROM ({self.get_returns_query()})
        )
        SELECT
            AVG(returns) * 252 as annualized_return,
            STDDEV(returns) * SQRT(252) as annualized_volatility,
            AVG(returns) / STDDEV(returns) * SQRT(252) as sharpe_ratio,
            MIN(cumulative_return) as max_drawdown
        FROM returns_data
        """

        result = athena.query_to_json(sql)
        return result[0] if result else {}
```

---

## ğŸ’° ë¹„ìš© ìƒì„¸ ë¶„ì„

### Athena ê°€ê²© êµ¬ì¡°

```
ê¸°ë³¸ ë¹„ìš©: $5 per TB scanned
ì••ì¶•/íŒŒí‹°ì…˜ ìµœì í™” ì‹œ: $0.25/ì›” ì˜ˆìƒ

ì˜ˆì‹œ:
- 1GB ë°ì´í„° ìŠ¤ìº”: $0.005
- 10GB ë°ì´í„° ìŠ¤ìº”: $0.05
- 100GB ë°ì´í„° ìŠ¤ìº”: $0.50

ì›” 100íšŒ ì¿¼ë¦¬ Ã— í‰ê·  50MB ìŠ¤ìº”:
â†’ 100 Ã— 50MB = 5GB = 0.005TB
â†’ 0.005TB Ã— $5 = $0.025/ì›”

íŒŒí‹°ì…˜ í”„ë£¨ë‹ìœ¼ë¡œ 70% ê°ì†Œ:
â†’ $0.025 Ã— 0.3 = $0.0075/ì›”

ì‹¤ì œ ì˜ˆìƒ: $0.25/ì›” (ì—¬ìœ  í¬í•¨)
```

### ìµœì¢… ë¹„ìš© ë¹„êµ

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  êµ¬ì„± ìš”ì†Œ          â”‚ Athena   â”‚ Trino     â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  RDS (ë©”íƒ€)         â”‚ $14.43   â”‚ $14.43    â”‚
â”‚  S3 + Glue          â”‚ $0.15    â”‚ $0.15     â”‚
â”‚  Query Engine       â”‚ $0.25    â”‚ $12.60    â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  ì´ê³„               â”‚ $14.83   â”‚ $27.18    â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  í˜„ì¬ ëŒ€ë¹„ ì ˆê°     â”‚ 44%      â”‚ -3%       â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

Athena: ë¹„ìš© ì ˆê° + ì„œë²„ë¦¬ìŠ¤
Trino: ë” ë¹ ë¥¸ ì‘ë‹µ + ë” ê°•ë ¥í•œ ê¸°ëŠ¥
```

---

## ğŸ¯ Athena vs Trino ìµœì¢… ì„ íƒ ê°€ì´ë“œ

### Athenaë¥¼ ì„ íƒí•´ì•¼ í•  ë•Œ â­â­â­â­â­

```
âœ… ë¹„ìš©ì´ ìµœìš°ì„ 
âœ… ì¸í”„ë¼ ê´€ë¦¬ í•˜ê³  ì‹¶ì§€ ì•ŠìŒ
âœ… ì„œë²„ë¦¬ìŠ¤ ì„ í˜¸
âœ… 3-5ì´ˆ ì§€ì—° í—ˆìš© ê°€ëŠ¥
âœ… ì¿¼ë¦¬ ë¹ˆë„ ë‚®ìŒ (< 1000íšŒ/ì¼)
âœ… ë°°ì¹˜/ë¶„ì„ ìœ„ì£¼
âœ… AWS ë„¤ì´í‹°ë¸Œ í†µí•© ì„ í˜¸
```

### Trinoë¥¼ ì„ íƒí•´ì•¼ í•  ë•Œ

```
âœ… ì¦‰ì‹œ ì‘ë‹µ í•„ìš” (< 500ms)
âœ… ì‹¤ì‹œê°„ ëŒ€ì‹œë³´ë“œ
âœ… ì¿¼ë¦¬ ë¹ˆë„ ë†’ìŒ (> 10000íšŒ/ì¼)
âœ… ë³µì¡í•œ ìµœì í™” í•„ìš”
âœ… ì—¬ëŸ¬ ë°ì´í„° ì†ŒìŠ¤ ë™ì‹œ ì ‘ê·¼ (Kafka, Cassandra ë“±)
âœ… ê´€ë¦¬ ë¦¬ì†ŒìŠ¤ ìˆìŒ
```

---

## ğŸš€ Athena êµ¬í˜„ ì²´í¬ë¦¬ìŠ¤íŠ¸

### Phase 1: ì„¤ì • (1-2ì¼)

```bash
# 1. S3 ë²„í‚· ìƒì„±
aws s3 mb s3://insight-invest-datalake
aws s3 mb s3://insight-invest-athena-results

# 2. Glue ë°ì´í„°ë² ì´ìŠ¤ ìƒì„±
aws glue create-database --database-input '{"Name": "market_data"}'
aws glue create-database --database-input '{"Name": "portfolio"}'
aws glue create-database --database-input '{"Name": "analytics"}'

# 3. IAM ì—­í•  ì„¤ì •
aws iam attach-role-policy \
  --role-name insight-invest-task-role \
  --policy-arn arn:aws:iam::aws:policy/AmazonAthenaFullAccess
```

### Phase 2: í…Œì´ë¸” ìƒì„± (2-3ì¼)

```python
# PyIcebergë¡œ Iceberg í…Œì´ë¸” ìƒì„±
python scripts/create_iceberg_tables_athena.py
```

### Phase 3: API í†µí•© (3-5ì¼)

```python
# FastAPIì— Athena í´ë¼ì´ì–¸íŠ¸ í†µí•©
pip install boto3 pyarrow s3fs

# ë¼ìš°í„° ì¶”ê°€
from app.routers import price_athena
app.include_router(price_athena.router)
```

### Phase 4: í…ŒìŠ¤íŠ¸ (2-3ì¼)

```python
# ì¿¼ë¦¬ í…ŒìŠ¤íŠ¸
result = athena.query_to_json("""
    SELECT * FROM market_data.us_stocks_price
    LIMIT 10
""")

# í¬ë¡œìŠ¤ ìŠ¤í‚¤ë§ˆ ì¡°ì¸ í…ŒìŠ¤íŠ¸
result = athena.query_to_json("""
    SELECT *
    FROM market_data.us_stocks_price p
    JOIN portfolio.tb_nav n ON p.trade_date = n.trade_date
    LIMIT 10
""")
```

---

## ğŸ’¡ Athena ìµœì í™” íŒ

### 1. íŒŒí‹°ì…˜ í”„ë£¨ë‹

```sql
-- âŒ ë‚˜ìœ ì˜ˆ: ì „ì²´ ìŠ¤ìº”
SELECT *
FROM market_data.us_stocks_price
WHERE meta_id = 123

-- âœ… ì¢‹ì€ ì˜ˆ: íŒŒí‹°ì…˜ í•„í„°
SELECT *
FROM market_data.us_stocks_price
WHERE trade_date >= DATE '2024-11-01'  -- íŒŒí‹°ì…˜ ì»¬ëŸ¼!
  AND trade_date < DATE '2024-12-01'
  AND meta_id = 123

-- ìŠ¤ìº”ëŸ‰: 10GB â†’ 300MB (97% ê°ì†Œ!)
```

### 2. ì»¬ëŸ¼ í”„ë¡œì ì…˜

```sql
-- âŒ ë‚˜ìœ ì˜ˆ: ëª¨ë“  ì»¬ëŸ¼
SELECT *
FROM market_data.us_stocks_price

-- âœ… ì¢‹ì€ ì˜ˆ: í•„ìš”í•œ ì»¬ëŸ¼ë§Œ
SELECT trade_date, adj_close
FROM market_data.us_stocks_price

-- ìŠ¤ìº”ëŸ‰: 1GB â†’ 200MB (80% ê°ì†Œ!)
```

### 3. CTAS (Create Table As Select)

```sql
-- ìì£¼ ì‚¬ìš©í•˜ëŠ” ì¿¼ë¦¬ëŠ” ë¯¸ë¦¬ ê³„ì‚°í•˜ì—¬ ì €ì¥
CREATE TABLE analytics.daily_portfolio_value
WITH (
  format = 'PARQUET',
  parquet_compression = 'ZSTD',
  partitioned_by = ARRAY['trade_date']
) AS
SELECT
  trade_date,
  port_id,
  SUM(adj_close * weight) as portfolio_value
FROM market_data.us_stocks_price p
JOIN portfolio.tb_rebalance r ON p.meta_id = r.meta_id
GROUP BY trade_date, port_id

-- ì´í›„ ë¹ ë¥¸ ì¡°íšŒ
SELECT * FROM analytics.daily_portfolio_value
WHERE port_id = 1
```

---

## ğŸ“ í•™ìŠµ ìë£Œ

- [Athena Iceberg Support](https://docs.aws.amazon.com/athena/latest/ug/querying-iceberg.html)
- [Athena Query Optimization](https://docs.aws.amazon.com/athena/latest/ug/performance-tuning.html)
- [PyArrow Documentation](https://arrow.apache.org/docs/python/)

---

## ğŸ¯ ìµœì¢… ì¶”ì²œ

### ë‹¹ì‹ ì˜ í”„ë¡œì íŠ¸ì—ëŠ” **Athenaê°€ ë” ë‚˜ì„ ìˆ˜ ìˆìŠµë‹ˆë‹¤!**

#### ì´ìœ :
1. âœ… **Pandas ì œê±°** ê°€ëŠ¥ (Arrow ë„¤ì´í‹°ë¸Œ)
2. âœ… **í¬ë¡œìŠ¤ ìŠ¤í‚¤ë§ˆ ì¡°ì¸** ì™„ë²½ ì§€ì›
3. âœ… **ë¶„ì‚° ì²˜ë¦¬** ìë™
4. âœ… **ë¹„ìš©** ì›” $0.25 (Trinoì˜ 1/50)
5. âœ… **ì¸í”„ë¼ ê´€ë¦¬** ë¶ˆí•„ìš” (ì„œë²„ë¦¬ìŠ¤)
6. âœ… **í™•ì¥ì„±** ë¬´í•œ
7. âš ï¸ **ì‘ë‹µ ì‹œê°„** 3-5ì´ˆ (í—ˆìš© ê°€ëŠ¥í•˜ë©´ ìµœê³ ì˜ ì„ íƒ)

#### ì„ íƒ ê¸°ì¤€:
```
ì‘ë‹µ ì‹œê°„ > 3ì´ˆ í—ˆìš© â†’ Athena â­â­â­â­â­
ì‘ë‹µ ì‹œê°„ < 500ms í•„ìˆ˜ â†’ Trino
```

ëŒ€ë¶€ë¶„ì˜ ë°±í…ŒìŠ¤íŠ¸/ë¶„ì„ APIëŠ” 3ì´ˆ ì •ë„ ì¶©ë¶„í•˜ë¯€ë¡œ **Athena ê°•ë ¥ ì¶”ì²œ**í•©ë‹ˆë‹¤! ğŸ‰
